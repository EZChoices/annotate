"""Adjudication workflow API.

This module exposes a thin FastAPI application that wraps the adjudication
queue JSON files generated by the nightly scripts.  The endpoints are designed
so that the dashboard can safely mutate queue records without risking data
loss when multiple reviewers act concurrently.
"""

from __future__ import annotations

import json
import logging
import os
import shutil
import tempfile
from contextlib import contextmanager
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Iterable, List, Optional

from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel, Field


LOGGER = logging.getLogger("adjudication_api")
if not LOGGER.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
    handler.setFormatter(formatter)
    LOGGER.addHandler(handler)
LOGGER.setLevel(logging.INFO)


def _env_path(key: str, default: Path) -> Path:
    value = os.environ.get(key)
    if value:
        return Path(value).expanduser().resolve()
    return default


ROOT_DIR = Path(__file__).resolve().parents[1]
REVIEW_DIR = _env_path("ADJUDICATION_OUTPUT_DIR", ROOT_DIR / "data" / "review")
QUEUE_PATH = REVIEW_DIR / "adjudication_queue.json"
STAGE2_OUTPUT_DIR = _env_path("STAGE2_OUTPUT_DIR", ROOT_DIR / "data" / "stage2_output")


class AssignRequest(BaseModel):
    asset_id: str = Field(..., alias="asset_id")
    assignee: str


class PromoteRequest(BaseModel):
    asset_id: str = Field(..., alias="asset_id")
    adjudicator_id: str = Field(..., alias="adjudicator_id")


class StatusRequest(BaseModel):
    asset_id: str = Field(..., alias="asset_id")
    status: str


@dataclass
class QueueUpdateResult:
    record: dict
    queue: List[dict]


@contextmanager
def _file_lock(lock_path: Path) -> Iterable[None]:
    """Simple advisory file lock based on ``fcntl`` (POSIX only)."""

    lock_path.parent.mkdir(parents=True, exist_ok=True)
    fd = os.open(lock_path, os.O_RDWR | os.O_CREAT)
    try:
        try:
            import fcntl  # type: ignore

            fcntl.flock(fd, fcntl.LOCK_EX)
        except ImportError:  # pragma: no cover - non POSIX platforms
            pass
        yield
    finally:
        try:
            import fcntl  # type: ignore

            fcntl.flock(fd, fcntl.LOCK_UN)
        except ImportError:  # pragma: no cover - non POSIX platforms
            pass
        os.close(fd)


def _read_queue() -> List[dict]:
    if not QUEUE_PATH.is_file():
        return []
    try:
        text = QUEUE_PATH.read_text(encoding="utf-8")
    except FileNotFoundError:
        return []
    if not text.strip():
        return []
    try:
        data = json.loads(text)
    except json.JSONDecodeError as exc:  # pragma: no cover - corrupt file
        raise HTTPException(500, f"Queue file is corrupted: {exc}")
    if not isinstance(data, list):
        return []
    records: List[dict] = []
    for entry in data:
        if isinstance(entry, dict) and entry.get("asset_id"):
            records.append(dict(entry))
    return records


def _atomic_write_json(path: Path, payload: object) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with tempfile.NamedTemporaryFile(
        "w", encoding="utf-8", dir=str(path.parent), delete=False
    ) as handle:
        json.dump(payload, handle, ensure_ascii=False, indent=2)
        handle.write("\n")
        temp_name = handle.name
    os.replace(temp_name, path)


def _current_timestamp() -> str:
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")


def _get_actor(request: Request, fallback: Optional[str] = None) -> str:
    header_keys = [
        "x-user-id",
        "x-actor-id",
        "x-client-id",
        "x-annotator-id",
        "x-user",
    ]
    for key in header_keys:
        value = request.headers.get(key)
        if value:
            return value
    if fallback:
        return fallback
    return "anonymous"


def _update_queue_record(
    predicate_asset_id: str,
    mutator,
) -> QueueUpdateResult:
    queue = _read_queue()
    record = None
    for idx, entry in enumerate(queue):
        if entry.get("asset_id") == predicate_asset_id:
            record = mutator(dict(entry))
            queue[idx] = record
            break
    if record is None:
        raise HTTPException(404, f"Asset {predicate_asset_id} is not in the adjudication queue")
    _atomic_write_json(QUEUE_PATH, queue)
    return QueueUpdateResult(record=record, queue=queue)


def _load_json(path: Path) -> Optional[dict]:
    try:
        text = path.read_text(encoding="utf-8")
    except FileNotFoundError:
        return None
    if not text.strip():
        return None
    try:
        data = json.loads(text)
    except json.JSONDecodeError as exc:
        raise HTTPException(500, f"Corrupted JSON at {path}: {exc}")
    if isinstance(data, dict):
        return data
    return None


def _copy_tree(src: Path, dst: Path) -> None:
    if not src.exists():
        return
    for root, dirs, files in os.walk(src):
        rel = Path(root).relative_to(src)
        target_root = dst / rel
        target_root.mkdir(parents=True, exist_ok=True)
        for name in files:
            src_path = Path(root) / name
            dst_path = target_root / name
            shutil.copy2(src_path, dst_path)


def _select_latest_pass_dir(asset_dir: Path) -> Optional[Path]:
    candidates: List[tuple[int, float, Path]] = []
    for path in asset_dir.rglob("pass_*"):
        if not path.is_dir():
            continue
        if "merged" in {segment.lower() for segment in path.parts}:
            continue
        segment = path.name.lower()
        if not segment.startswith("pass"):
            continue
        suffix = segment.split("pass")[-1]
        try:
            number = int("".join(ch for ch in suffix if ch.isdigit()))
        except ValueError:
            continue
        try:
            mtime = path.stat().st_mtime
        except OSError:
            mtime = 0.0
        candidates.append((number, mtime, path))
    if not candidates:
        return None
    candidates.sort(key=lambda item: (item[0], item[1]), reverse=True)
    return candidates[0][2]


def _prepare_merged_directory(asset_dir: Path) -> Path:
    merged_dir = asset_dir / "merged"
    temp_dir = Path(
        tempfile.mkdtemp(prefix="merged_tmp_", dir=str(asset_dir))
    )

    existing_dir = merged_dir if merged_dir.is_dir() else None
    if existing_dir:
        _copy_tree(existing_dir, temp_dir)

    latest_pass_dir = _select_latest_pass_dir(asset_dir)
    if latest_pass_dir:
        _copy_tree(latest_pass_dir, temp_dir)

    backup_dir: Optional[Path] = None
    if merged_dir.exists():
        backup_dir = asset_dir / f".merged_backup_{datetime.now().timestamp():.0f}"
        try:
            os.rename(merged_dir, backup_dir)
        except OSError:
            shutil.rmtree(temp_dir, ignore_errors=True)
            raise

    try:
        os.rename(temp_dir, merged_dir)
    except OSError as exc:
        if backup_dir and backup_dir.exists():
            os.rename(backup_dir, merged_dir)
        shutil.rmtree(temp_dir, ignore_errors=True)
        raise HTTPException(500, f"Failed to finalize merged directory: {exc}")

    if backup_dir and backup_dir.exists():
        shutil.rmtree(backup_dir, ignore_errors=True)

    return merged_dir


app = FastAPI()


@app.get("/api/adjudication/queue")
async def get_queue(status: Optional[str] = None, cell: Optional[str] = None, reason: Optional[str] = None):
    queue = _read_queue()

    def matches(entry: dict) -> bool:
        if status and entry.get("status") != status:
            return False
        if cell:
            cell_value = entry.get("cell") or entry.get("cell_key")
            if not cell_value or str(cell_value) != cell:
                return False
        if reason:
            reasons = entry.get("reasons") or []
            if isinstance(reasons, list):
                if reason not in reasons:
                    return False
            else:
                return False
        return True

    if status or cell or reason:
        queue = [entry for entry in queue if matches(entry)]
    return queue


@app.post("/api/adjudication/assign")
async def assign(request: Request, payload: AssignRequest):
    actor = _get_actor(request, payload.assignee)
    lock_path = QUEUE_PATH.with_suffix(".lock")
    with _file_lock(lock_path):
        def mutator(entry: dict) -> dict:
            if entry.get("status") != "pending":
                raise HTTPException(409, "Asset is no longer pending adjudication")
            entry["status"] = "assigned"
            entry["assignee"] = payload.assignee
            entry["last_seen_at"] = _current_timestamp()
            return entry

        result = _update_queue_record(payload.asset_id, mutator)

    LOGGER.info(
        "Queue assign asset=%s assignee=%s actor=%s",
        payload.asset_id,
        payload.assignee,
        actor,
    )
    return result.record


@app.post("/api/adjudication/status")
async def update_status(request: Request, payload: StatusRequest):
    actor = _get_actor(request)
    lock_path = QUEUE_PATH.with_suffix(".lock")
    normalized_status = (payload.status or "").strip()
    if not normalized_status:
        raise HTTPException(400, "Status must be provided")

    with _file_lock(lock_path):
        def mutator(entry: dict) -> dict:
            entry["status"] = normalized_status
            entry["last_seen_at"] = _current_timestamp()
            return entry

        result = _update_queue_record(payload.asset_id, mutator)

    LOGGER.info(
        "Queue status asset=%s status=%s actor=%s",
        payload.asset_id,
        normalized_status,
        actor,
    )
    return result.record


@app.post("/api/adjudication/promote")
async def promote(request: Request, payload: PromoteRequest):
    actor = _get_actor(request, payload.adjudicator_id)

    asset_dir = STAGE2_OUTPUT_DIR / payload.asset_id
    if not asset_dir.exists():
        raise HTTPException(404, f"Asset directory not found for {payload.asset_id}")

    asset_lock = asset_dir / ".adjudication.lock"
    queue_lock = QUEUE_PATH.with_suffix(".lock")
    with _file_lock(asset_lock):
        with _file_lock(queue_lock):

            def mutator(entry: dict) -> dict:
                status = (entry.get("status") or "").lower()
                if status not in {"assigned", "in_review"}:
                    raise HTTPException(409, "Asset is not ready for promotion")
                entry["status"] = "locked"
                entry["last_seen_at"] = _current_timestamp()
                entry["adjudicator_id"] = payload.adjudicator_id
                return entry

            result = _update_queue_record(payload.asset_id, mutator)

        merged_dir = _prepare_merged_directory(asset_dir)

        meta_path = asset_dir / "item_meta.json"
        meta = _load_json(meta_path) or {}
        adjudication = meta.get("adjudication")
        if not isinstance(adjudication, dict):
            adjudication = {}
        timestamp = result.record.get("last_seen_at") or _current_timestamp()
        adjudication.update(
            {
                "status": "locked",
                "adjudicator_id": payload.adjudicator_id,
                "decision_at": timestamp,
                "merged_path": str(merged_dir.relative_to(asset_dir)),
            }
        )
        meta["adjudication"] = adjudication
        meta["review_status"] = "locked"
        _atomic_write_json(meta_path, meta)

    LOGGER.info(
        "Queue promote asset=%s adjudicator=%s actor=%s",
        payload.asset_id,
        payload.adjudicator_id,
        actor,
    )
    return result.record


